# -*- coding: utf-8 -*-
"""Model_Building-checkpoint.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i2apJylkH89G5PZjqSPtCbhZ8ULLX6LO
"""

#!pip install numpy
#!pip install pandas
#!pip install xgboost
#! pip install
#!pip install statsmodels

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression,LassoCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error
from sklearn.model_selection import train_test_split

from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
import scipy.stats as stats

data = pd.read_csv(r'laptop_price.csv',encoding='latin1')
data.head()

# Identify How many rows and colums in the data set
data.shape

"""## Data preparation"""

# Then check the null values in the data set
data.isnull().sum()

# So there is no any missing values in tha data set
# Chech  another information in the data set(What are the type of the each varible)
data.info()
# Accoding to the below result there are different type of data. But in machine learning algorotham only
# can understand the numarical type data.So, we have to convart this object type data in to numarical by using one hot encoding

data['Ram'] = data['Ram'].str.replace('GB','').astype('int32')
data['Weight'] = data['Weight'].str.replace('kg','').astype('float32')
data.info()
# By using the above code Ram and  colum eke GB kiyana kalla ain karala e wenuwata blank ekak add karanawa,
#Then after convart that colums in to int32 type

# Identify is there any not corralated varible to the model
data[['Price_euros','Inches','Ram','Weight',]].corr()
# There is high corralation between the weight and inclues, So we can used one varible insted both

# Check the one by one colum and identify problem and fix that, First Company colum
data['Company'].value_counts()

# There are 19 comapany. Also some brand do not have much data. That mean that varible can not effect thatmuch to the model, I conbine it and make variable called others.Consider majory barand available in the market.
def add_company (input):
    if input == 'Samsung' or input == 'Mediacom' or input == 'Razer' or input == 'Microsoft' or input == 'Vero' or input == 'Xiaomi' or input == 'Chuwi' or input == 'Fujitsu' or input == 'Google' or input == 'LG' or input == 'Huawei':
        return 'Others'
    else:
        return input

data['Company'] = data['Company'].apply(add_company)

data['Company'].value_counts()
# Make the data set as below.

data['TypeName'].value_counts()

data.info()

# Then move on to the CPU colum and idetify the unique value
len(data['Cpu'].value_counts())
# But there is major prblem,there are different model type, first to get idea of what are the major branda , We remove the tail part of the name

data['CPU_name'] = data['Cpu'].apply(lambda x:" ".join(x.split()[0:3]))
data['CPU_name'].value_counts()
# By looking at the fallowingdata we can say there are major branda in the data set and we turn rest in to othere catergary, Also all the AMD type put in the
#one type called AMD

def set_processor(name):
    if name == 'Intel Core i7' or name == 'Intel Core i5' or name == 'Intel Core i3':
        return name
    else:
        if name.split()[0] == 'AMD':
            return 'AMD'
        else:
            return 'Other'
data['CPU_name'] = data['CPU_name'].apply(set_processor)
data['CPU_name'].value_counts()
# Then I make the that colum appriatly

# Then move onto the GPU colum
len(data['Gpu'].value_counts())

# THis also the above problem, We do that as above
data['GPU_Name'] = data['Gpu'].apply(lambda x:"".join(x.split()[0:1]))
data['GPU_Name'].value_counts()

# We remove the row that only contain ARM
data = data[data['GPU_Name'] != 'ARM']
data.shape

# THen move on to the next colum oparation system
data['OpSys'].value_counts()
# We turn this in to majore commertial availble OS in Sri Lankan market, and remain put in to others,

def set_OS(input):
    if input == 'Windows 10' or input == 'Windows 7' or input == 'Windows 10 s':
        return 'Windows'
    elif input == 'macOS' or input == 'Mac OS x':
        return 'Mac'
    elif input == 'Linux' :
        return input
    else:
        return 'Other'

data['OpSys'] = data['OpSys'].apply(set_OS)
data['OpSys'].value_counts()

data.shape

data = data.drop(['Product','ScreenResolution','Cpu','Gpu','laptop_ID','Inches','ScreenResolution'],axis = 1)

data.shape

data.info()

data.head()

"""#### This is the end of the data preparation , Then lets move on to the  feature enginearing  part"""

# Lets devide the data set in to dependant and independant varible
x = data.drop('Price_euros',axis=1)
y = data['Price_euros']

x.shape

# Perform the one hot encoding for holl data set, First get the catagarical data separately and perform one hot encoding
catergarcal_data = ['Company','TypeName','OpSys','CPU_name','GPU_Name']
x[catergarcal_data].head()

# Now do the encoding part to this data set,
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
Encoded_data = encoder.fit_transform(x[catergarcal_data])
Encoded_data
# Sparse_output = False kiyanne pahalakiyana widihata denna epa kiyala
# When use this I learn new thing, after this encoded this make new array type called Spare matrix,
# When a array have lot of 0 and 1 values this matrix memorize only the position of the 1

Encoded_data.shape

encoded_cols = encoder.get_feature_names_out(catergarcal_data) # This get the colum names
encoded_df = pd.DataFrame(Encoded_data, columns=encoded_cols)
encoded_df.tail()
# Ater encoding we got the array.So we have to create an dataframe to,

# Here  I faced big problem, THe problemis when I combine my encoded and numarical values I got one row more, The problemis different indexing ,
# To overcome this I reseat the indxing
print(len(x),len(encoded_df))
print(x.index.difference(encoded_df.index))
print(encoded_df.index.difference(x.index))

# Above show the index are difference
x = x.reset_index(drop=True)
encoded_df = encoded_df.reset_index(drop=True)
final_x = pd.concat([x.drop(columns= catergarcal_data),encoded_df],axis=1)
final_x.shape

final_x.head()

# Get five number summary (min, Q1, median, Q3, max) for all numarical independent variables. Beacaues I have todecide whether is this shoid be scaled or not
summary = final_x[['Ram','Weight']].describe(percentiles=[0.25, 0.5, 0.75]).loc[['min', '25%', '50%', '75%', 'max']]
summary

y_summary = y.describe(percentiles=[0.25,0.5,0.75]).loc[['min', '25%', '50%', '75%', 'max']]
y_summary

"""##### The numarical value of the data set are not in the same range , so we have get them in to the same range. For that we used standerlization."""

# Create data set for standerlization
y = y.reset_index(drop=True)
final_x = final_x.reset_index(drop=True)

numaric_data = pd.concat([y,final_x['Ram'],final_x['Weight']],axis=1)
scaler = StandardScaler()
scale_numaric_data = scaler.fit_transform(numaric_data)
standed_numaric_data = pd.DataFrame(scale_numaric_data,columns=numaric_data.columns)
standed_numaric_data.head()
# Then convart all the numaric data in to scaler. Now we have to make x and y varible again

y = standed_numaric_data['Price_euros']

x = pd.concat([final_x.drop(columns=['Ram','Weight']),standed_numaric_data[['Ram','Weight']]],axis=1)

#final_x = pd.concat([x.drop(columns= catergarcal_data),encoded_df],axis=1)
#final_x.head()

x.shape,y.shape

x.head(),y.head()

"""Ok, Now data set is ready to build the model, Then build the model, lets start this in simple algorithams and then try complecated algorithams"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Testing each algoritham by and identify which one is the best for our model
# Apply cross validation for the Linear Regression model
Rergression_model = LinearRegression()
cross_val_score(Rergression_model,x_train,y_train,cv=10).mean()

"""##### Check the assumption of the linear regression"""

Rergression_model.fit(x_train,y_train)

y_pred = Rergression_model.predict(x_test)
y_train_pred = Rergression_model.predict(x_train)

Accuracy = r2_score(y_test,y_pred)
MSE = mean_squared_error(y_test,y_pred)
MAE = mean_absolute_error(y_test,y_pred)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")

# Above accuracy is not that much good for predict the model, also MSE and MAE are quite big.
# Multiple lenaer regressionisnot that much good for this prediction. Some time this do not have lener relation ship

plt.scatter(y_train, y_train_pred)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Linearity Check: Actual vs Predicted")
plt.axline((0, 0), slope=1, color='red', linestyle='--')
plt.show()

residuals = y_train - y_train_pred
dw = sm.stats.stattools.durbin_watson(residuals)
dw
# Accoding to the below output we can say This hold the leanearity
# Because burbing_waston test resuilt in between 1.5 and 2.5

plt.scatter(y_train_pred, residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted")
plt.ylabel("Residuals")
plt.title("Homoscedasticity Check")
plt.show()

sm.qqplot(residuals, line='45')
plt.title("Normal Q-Q Plot")
plt.show()

"""##### So, This is not satisfy the the normality of residuls,We cannot apply the multiple lranear regressionmodel"""

# Apply crossvalidation to the Lasso model
Lasso_model = LassoCV()
cross_val_score(Lasso_model,x_train,y_train,cv=10).mean()

# Apply cross validation to the Decision Tree model
D_Tre_model = DecisionTreeRegressor()
cross_val_score(D_Tre_model,x_train,y_train,cv=10).mean()

# Apply cross validation to the KNeighbors model
KN_model = KNeighborsRegressor()
cross_val_score(KN_model,x_train,y_train,cv=10).mean()

# Apply cross validation to the SVM model
SVM_model = SVR()
cross_val_score(SVM_model,x_train,y_train,cv=10).mean()

"""###### Among above the algoritham K-nearest algoritham and SVM algoritham perform well,So as first step I am going to tune  hyper parameters above two parameters"""

from sklearn.model_selection import GridSearchCV

pram = {'n_neighbors': list(range(1, 21)),
        'weights': ['uniform', 'distance']}

# Tune the hyperparameters of The KNN algoritham
KN_model_grid_seach = GridSearchCV(KN_model,param_grid=pram,cv=10,scoring='r2')
KN_model_grid_seach.fit(x_train,y_train)

pred_KN_test = KN_model_grid_seach.predict(x_test)
pred_KN_train = KN_model_grid_seach.predict(x_train)

Accuracy = r2_score(y_test,pred_KN_test)
MSE = mean_squared_error(y_test,pred_KN_test)
MAE = mean_absolute_error(y_test,pred_KN_test)
train_accuracy = r2_score(y_train,pred_KN_train)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Training Accuracy: {train_accuracy}")

param_grid = {
    'C': [0.1, 1, 10, 100],           # Regularization strength
    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],
    'gamma': ['scale', 'auto']        # Kernel coefficient
}
SVM_grid_search = GridSearchCV(SVM_model, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)
SVM_grid_search.fit(x_train, y_train)

pred_SVM_test = SVM_grid_search.predict(x_test)
pred_SVM_train = SVM_grid_search.predict(x_train)

Accuracy = r2_score(y_test,pred_SVM_test)
MSE = mean_squared_error(y_test,pred_SVM_test)
MAE = mean_absolute_error(y_test,pred_SVM_test)
train_accuracy = r2_score(y_train,pred_SVM_train)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Training Accuracy: {train_accuracy}")

"""##### Upto here we try the multiple leaner regression model,Lasso regression model,KNN,SVR and decision tree. Among these algorithmas when we used cross validation KNN perform the best. After hyper parametric tune that gives the 0.8 accuracy.Lets try to increte this acuracy.

#### To improve the model accuracy, apply the Ensemble Methods. Like Bagging,Boosting,stacking,voting.First apply the Random forest algoritham.
"""

from sklearn.ensemble import RandomForestRegressor
R_forest_model = RandomForestRegressor(n_estimators=100)
cross_val_score(R_forest_model,x_train,y_train,cv=10,).mean()

from xgboost import XGBRegressor
XG_boost_model = XGBRegressor(n_estimators=100, learning_rate=0.1)
cross_val_score(XG_boost_model,x_train,y_train,cv=10,).mean()



XG_boost_model.fit(x_train,y_train)
y_pred_XG = XG_boost_model.predict(x_test)
y_pred_XG_train = XG_boost_model.predict(x_train)

Accuracy = r2_score(y_test,y_pred_XG)
MSE = mean_squared_error(y_test,y_pred_XG)
MAE = mean_absolute_error(y_test,y_pred_XG)
train_accuracy = r2_score(y_train,y_pred_XG_train)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Training Accuracy: {train_accuracy}")

#from sklearn.model_selection import GridSearchCV

pram = {'n_neighbors': list(range(1, 21)),
        'weights': ['uniform', 'distance']}

# Tune the hyperparameters of The KNN algoritham
grid_seach = GridSearchCV(KN_model,param_grid=pram,cv=10,scoring='r2')
grid_seach.fit(x_train,y_train)

# AMong of these ansemble methods XG boost show I accuracy but thses two show
# nearly same accury so , I tune the both parameters

pram_RF ={
    'n_estimators': [100, 200, 300, 500],
    'max_depth': [None, 10, 20, 30, 40],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2'],
    'bootstrap': [True, False]
}

grid_seach_RF = GridSearchCV(R_forest_model,param_grid=pram_RF,cv=10,scoring='r2',n_jobs=5)
grid_seach_RF.fit(x_train,y_train)

grid_seach_RF.best_params_

grid_seach_RF.score(x_test, y_test)

from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV


# Define parameter grid
param_grid_xgb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 5],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

#Grid Search
grid_search_xgb = GridSearchCV(
    estimator=XG_boost_model ,
    param_grid=param_grid_xgb,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=2
)

# Fit
grid_search_xgb.fit(x_train, y_train)

# Best model and parameters
best_xgb_model = grid_search_xgb.best_estimator_
print("Best Parameters (XGBoost):", grid_search_xgb.best_params_)

y_pred_xgb = best_xgb_model.predict(x_test)
y_pred_xgb_train = best_xgb_model.predict(x_train)

Accuracy = r2_score(y_test,y_pred_xgb)
MSE = mean_squared_error(y_test,y_pred_xgb)
MAE = mean_absolute_error(y_test,y_pred_xgb)
train_accuracy = r2_score(y_train,y_pred_xgb_train)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Training Accuracy: {train_accuracy}")

best_xgb_model.score(x_train,y_train)

"""#### Up to here I  used advance machine learning approches. But I got only 0.8 accuracy of this model. Now I move on to the early part of the modelbuilding pipline and do feature enginearing again. THat mean I apply principle component analysis(PCA). First I try by using two independant numarical varible  make one PCA varibe . Then I try used two PCA varible."""

x = pd.concat([final_x.drop(columns=['Ram','Weight']),standed_numaric_data[['Ram','Weight']]],axis=1)

#final_x = pd.concat([x.drop(columns= catergarcal_data),encoded_df],axis=1)
#final_x.head()

from sklearn.decomposition import PCA
x_numaric = x[['Ram','Weight']]
PCA1 = PCA(n_components=1)
x_pca = PCA1.fit_transform(x_numaric)
x_pca.shape

# After Creating new independant varible called "PCA1". Make the new x varible
PCA_1_x = x.drop(columns=['Ram','Weight'],inplace=False)
PCA_1_x = pd.concat([PCA_1_x,pd.DataFrame(x_pca,columns=['PCA1'])],axis=1)
PCA_1_x.head()

# Split the data set
x_train, x_test, y_train, y_test = train_test_split(PCA_1_x, y, test_size=0.2, random_state=42)

# Then perform the KNN algoritham for this new dataset
# Apply cross validation to the KNeighbors model
KN_model_PCA1 = KNeighborsRegressor()
cross_val_score(KN_model_PCA1,x_train,y_train,cv=10).mean()

y_pred_KN_PCA1 = KN_model.fit(x_train,y_train).predict(x_test)
y_pred_KN_train_PCA1 = KN_model.fit(x_train,y_train).predict(x_train)
Accuracy = r2_score(y_test,y_pred_KN_PCA1)
MSE = mean_squared_error(y_test,y_pred_KN_PCA1)
MAE = mean_absolute_error(y_test,y_pred_KN_PCA1)
train_accuracy = r2_score(y_train,y_pred_KN_train_PCA1)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Train_accuracy: {train_accuracy}")

# Perform the randomforestalgoritham for the new data set
R_forest_model_PCA1 = RandomForestRegressor(n_estimators=100)
cross_val_score(R_forest_model_PCA1,x_train,y_train,cv=10,).mean()

y_pred_R_PCA1 = R_forest_model_PCA1.fit(x_train,y_train).predict(x_test)
y_pred_R_train_PCA1 = R_forest_model_PCA1.fit(x_train,y_train).predict(x_train)
Accuracy = r2_score(y_test,y_pred_R_PCA1)
MSE = mean_squared_error(y_test,y_pred_R_PCA1)
MAE = mean_absolute_error(y_test,y_pred_R_PCA1)
train_accuracy = r2_score(y_train,y_pred_R_train_PCA1)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Train_accuracy: {train_accuracy}")

from xgboost import XGBRegressor
XG_boost_model_PCA1 = XGBRegressor(n_estimators=100, learning_rate=0.1)
cross_val_score(XG_boost_model_PCA1,x_train,y_train,cv=10,).mean()

# Define parameter grid
param_grid_xgb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 5],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

#Grid Search
grid_search_xgb_PCA1 = GridSearchCV(
    estimator=XG_boost_model_PCA1 ,
    param_grid=param_grid_xgb,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=2
)

# Fit
grid_search_xgb_PCA1.fit(x_train, y_train)

# Best model and parameters
best_xgb_model_PCA1 = grid_search_xgb_PCA1.best_estimator_
print("Best Parameters (XGBoost):", grid_search_xgb_PCA1.best_params_)

y_pred_XG_PCA1 = best_xgb_model_PCA1.fit(x_train,y_train).predict(x_test)
y_pred_XG_train_PCA1 = best_xgb_model_PCA1.fit(x_train,y_train).predict(x_train)
Accuracy = r2_score(y_test,y_pred_XG_PCA1)
MSE = mean_squared_error(y_test,y_pred_XG_PCA1)
MAE = mean_absolute_error(y_test,y_pred_XG_PCA1)
train_accuracy = r2_score(y_train,y_pred_XG_train_PCA1)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Train_accuracy: {train_accuracy}")

"""#### Here I try get two PCA varibles and build the model"""

# Now create the two PCA varibles and perform the model.
x_numaric = x[['Ram','Weight']]
PCA2 = PCA(n_components=2)
x_pca2 = PCA2.fit_transform(x_numaric)
x_pca2.shape

PCA_2_x = x.drop(columns=['Ram','Weight'],inplace=False)
PCA_2_x = pd.concat([PCA_2_x,pd.DataFrame(x_pca2,columns=['PCA1','PCA2'])],axis=1)
PCA_2_x.head()

# Split the data set
x_train, x_test, y_train, y_test = train_test_split(PCA_2_x, y, test_size=0.2, random_state=42)

# Then perform the KNN algoritham for this new dataset
# Apply cross validation to the KNeighbors model
KN_model_PCA2 = KNeighborsRegressor()
cross_val_score(KN_model_PCA2,x_train,y_train,cv=10).mean()

y_pred_KN_PCA2 = KN_model_PCA2.fit(x_train,y_train).predict(x_test)
y_pred_KN_train_PCA2 = KN_model_PCA2.fit(x_train,y_train).predict(x_train)
Accuracy = r2_score(y_test,y_pred_KN_PCA2)
MSE = mean_squared_error(y_test,y_pred_KN_PCA2)
MAE = mean_absolute_error(y_test,y_pred_KN_PCA2)
train_accuracy = r2_score(y_train,y_pred_KN_train_PCA2)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Train_accuracy: {train_accuracy}")

R_forest_model_PCA2 = RandomForestRegressor(n_estimators=100)
cross_val_score(R_forest_model_PCA2,x_train,y_train,cv=10,).mean()

y_pred_R_PCA2 = R_forest_model_PCA2.fit(x_train,y_train).predict(x_test)
y_pred_R_train_PCA2 = R_forest_model_PCA2.fit(x_train,y_train).predict(x_train)

Accuracy = r2_score(y_test,y_pred_R_PCA2)
MSE = mean_squared_error(y_test,y_pred_R_PCA2)
MAE = mean_absolute_error(y_test,y_pred_R_PCA2)
train_accuracy = r2_score(y_train,y_pred_R_train_PCA2)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Train_accuracy: {train_accuracy}")

x_train = x_train.values
y_train = y_train.values
XG_boost_model_PCA2 = XGBRegressor(n_estimators=100, learning_rate=0.1)
cross_val_score(XG_boost_model_PCA2,x_train,y_train,cv=10,).mean()

# Tune the hyper parameters of the xgboost algoritham.
# Define parameter grid
param_grid_xgb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 5],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

#Grid Search
grid_search_xgb_PCA2 = GridSearchCV(
    estimator=XG_boost_model ,
    param_grid=param_grid_xgb,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=2
)

# Fit
grid_search_xgb_PCA2.fit(X, Y)

# Best model and parameters
best_xgb_model_PCA2 = grid_search_xgb_PCA2.best_estimator_
print("Best Parameters (XGBoost):", grid_search_xgb_PCA2.best_params_)

y_pred_XG_PCA2 = best_xgb_model_PCA2.fit(x_train,y_train).predict(x_test)
y_pred_XG_train_PCA2 = best_xgb_model_PCA2.fit(x_train,y_train).predict(x_train)

Accuracy = r2_score(y_test,y_pred_XG_PCA2)
MSE = mean_squared_error(y_test,y_pred_XG_PCA2)
MAE = mean_absolute_error(y_test,y_pred_XG_PCA2)
train_accuracy = r2_score(y_train,y_pred_XG_train_PCA2)
print(f"Accuracy: {Accuracy}")
print(f"MSE: {MSE}")
print(f"MAE: {MAE}")
print(f"Train_accuracy: {train_accuracy}")

"""#### Now save the model, scaler,encoder and PCA for the build the web application"""

import pickle
with open('scaler.pkl','wb')as f:
  pickle.dump(scaler,f)

with open('encoder.pkl','wb')as f:
  pickle.dump(encoder,f)

with open ('PCA.pkl','wb')as f:
  pickle.dump(PCA2,f)

with open ('final_model.pkl','wb')as f:
  pickle.dump(best_xgb_model_PCA2,f)